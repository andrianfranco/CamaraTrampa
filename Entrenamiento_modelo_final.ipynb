{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "###################################### Librerias utilizadas ###################################\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input\n",
    "#from keras.optimizer import adam_v2\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator     # Generador de imagenes.\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "# Librerias para metricas de desempeño y matriz de confusion\n",
    "from sklearn import metrics                                  # Funcion para el calculo de metricas de desempeño, la de abajo hace lo mismo pero todo por separado.\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, precision_score, recall_score, accuracy_score, roc_auc_score\n",
    "from mlxtend.plotting import plot_confusion_matrix           # Paquete para ver matriz  de confusion en interfaz grafica.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "#Librerias para Generar data Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#Libreria para cargar modelo\n",
    "from keras.models import load_model\n",
    "\n",
    "# Libreria para obtener ruta de archivo actual\n",
    "import pathlib\n",
    "\n",
    "################################# Ingreso de parametros #########################################\n",
    "\n",
    "pathInicial = str(pathlib.Path().absolute()) + \"\\\\\" # Path obtenido: ~/modelo\n",
    "\n",
    "print(\"**** Ingreso de parametros ****\\n\")\n",
    "\n",
    "tipoModelo = int(input(\"Tipo de modelo: \\n Diurno --> Ingresar 0 \\n Nocturno --> Ingresar 1\\n\"))\n",
    "if not tipoModelo:\n",
    "    tipoModelo = \"Diurno\"\n",
    "else:\n",
    "    tipoModelo = \"Nocturno\" \n",
    "\n",
    "modelVGG = int(input(\" Modelo a utilizar: \\n VGG16 --> Ingresar 0 \\n VGG19 --> Ingresar 1\\n\"))\n",
    "if not modelVGG:\n",
    "    modelVGG = 16\n",
    "else:\n",
    "    modelVGG = 19 \n",
    "\n",
    "epochs      = int(input(\" Cantidad de epocas: \\n\"))\n",
    "batch_size  = int(input(\" Cantidad de muestras por actualización: \\n\"))\n",
    "num_classes = int(input(\" Número de clases: \\n\"))\n",
    "\n",
    "################################# Configuracion de parametros ###################################\n",
    "\n",
    "width_shape  = 224       # Ancho de imagen (Ancho tipico de VGG16 y VGG19)\n",
    "height_shape = 224       # Alto  de imagen (Alto tipico de VGG16 y VGG19)\n",
    "#num_classes  = 6        # Carpincho, Ciervo, Gato montés, Oveja, Puma, Vaca\n",
    "#epochs       = 500      # Numero de epocas de entrenamiento\n",
    "#batch_size   = 16       # Numero de muestras procesadas en cada actualizacion.\n",
    "#modelVGG     = 16       # 16: VGG16 - 19: VGG19\n",
    "#tipoModelo   = \"Diurno\" # \"Diurno\" o \"Nocturno\"\n",
    "\n",
    "################################# Directorios ##################################################\n",
    "\n",
    "model_dir               = pathInicial + r\"model_VGG\"+str(modelVGG)+\"_\"+str(epochs)+\"E_\"+str(batch_size)+\"B_\"+tipoModelo+\".h5\" \n",
    "\n",
    "if tipoModelo == \"Diurno\":\n",
    "    train_data_dir      = pathInicial + r\"imagenes_diurnas\\Entrenamiento\" # Path de entrenamiento\n",
    "    validation_data_dir = pathInicial + r\"imagenes_diurnas\\Validacion\"    # Path de validacion\n",
    "    test_data_dir       = pathInicial + r\"imagenes_diurnas\\Test\"          # Ruta de los datos a testear\n",
    "\n",
    "else: #tipoModelo == \"Nocturno\"\n",
    "    train_data_dir      = pathInicial + r\"imagenes_nocturnas\\Entrenamiento\" # Path de entrenamiento\n",
    "    validation_data_dir = pathInicial + r\"imagenes_nocturnas\\Validacion\"    # Path de validacion\n",
    "    test_data_dir       = pathInicial + r\"imagenes_nocturnas\\Test\"          # Ruta de los datos a testear\n",
    "\n",
    "############################### Excepciones ####################################################\n",
    "    \n",
    "cantTrainData = len(os.listdir(train_data_dir+\"\\\\\"+\"Carpincho\"+\"\\\\\"))      * len(os.listdir(train_data_dir+\"\\\\\"+\"Ciervo\"+\"\\\\\"))      * len(os.listdir(train_data_dir+\"\\\\\"+\"Gato montes\"+\"\\\\\"))      * len(os.listdir(train_data_dir+\"\\\\\"+\"Oveja\"+\"\\\\\"))      * len(os.listdir(train_data_dir+\"\\\\\"+\"Puma\"+\"\\\\\"))      * len(os.listdir(train_data_dir+\"\\\\\"+\"Vaca\"+\"\\\\\"))\n",
    "cantValData   = len(os.listdir(validation_data_dir+\"\\\\\"+\"Carpincho\"+\"\\\\\")) * len(os.listdir(validation_data_dir+\"\\\\\"+\"Ciervo\"+\"\\\\\")) * len(os.listdir(validation_data_dir+\"\\\\\"+\"Gato montes\"+\"\\\\\")) * len(os.listdir(validation_data_dir+\"\\\\\"+\"Oveja\"+\"\\\\\")) * len(os.listdir(validation_data_dir+\"\\\\\"+\"Puma\"+\"\\\\\")) * len(os.listdir(validation_data_dir+\"\\\\\"+\"Vaca\"+\"\\\\\"))\n",
    "cantTestData  = len(os.listdir(test_data_dir+\"\\\\\"+\"Carpincho\"+\"\\\\\"))       * len(os.listdir(test_data_dir+\"\\\\\"+\"Ciervo\"+\"\\\\\"))       * len(os.listdir(test_data_dir+\"\\\\\"+\"Gato montes\"+\"\\\\\"))       * len(os.listdir(test_data_dir+\"\\\\\"+\"Oveja\"+\"\\\\\"))       * len(os.listdir(test_data_dir+\"\\\\\"+\"Puma\"+\"\\\\\"))       * len(os.listdir(test_data_dir+\"\\\\\"+\"Vaca\"+\"\\\\\"))\n",
    "\n",
    "if (cantTrainData == 0) or (cantValData == 0) or (cantTestData == 0):\n",
    "    raise ValueError(\"Uno o varios de los directorios de datos del modelo \" +tipoModelo+\" se encuentran vacios (Entrenamiento, Test o Validación)\") \n",
    "    \n",
    "################################## Data augmentation ###############################################\n",
    "\n",
    "# Generador de imagenes de entrenamiento para tener mayor cantidad de imagenes\n",
    "train_datagen = ImageDataGenerator(  \n",
    "    rotation_range         = 20,                # Rotacion de 20 grados\n",
    "    zoom_range             = 0.2,               # zoom de 0.2 (20%)\n",
    "    width_shift_range      = 0.1,               # Desplazamiento horizontal\n",
    "    height_shift_range     = 0.1,               # Vertical \n",
    "    horizontal_flip        = True,              # Rotacion horizontal\n",
    "    vertical_flip          = False,             # Rotacion vertical\n",
    "    preprocessing_function = preprocess_input)\n",
    "\n",
    "# Generador de imagenes de validacion para tener mayor cantidad de imagenes\n",
    "valid_datagen = ImageDataGenerator(    \n",
    "    rotation_range         = 20,\n",
    "    zoom_range             = 0.2,\n",
    "    width_shift_range      = 0.1,\n",
    "    height_shift_range     = 0.1,\n",
    "    horizontal_flip        = True,\n",
    "    vertical_flip          = False,\n",
    "    preprocessing_function = preprocess_input) \n",
    "\n",
    "# Direccion de imagenes de entrenamiento\n",
    "train_generator  = train_datagen.flow_from_directory(  \n",
    "    train_data_dir,                             # Direccion de imagenes de entrenamiento.\n",
    "    target_size  = (width_shape, height_shape), # Dimensiones de imagenes de entrenamiento.\n",
    "    batch_size   = batch_size,\n",
    "    #save_to_dir ='',                           # Aca ponemos una direccion si queremos guardar las imagenes transformadas y generadas.\n",
    "    class_mode   ='categorical')                # Tipo de clase, al ser mas de 2 pasa de ser binario a categorical.\n",
    "\n",
    "# Direccion de imagenes de entrenamiento\n",
    "validation_generator = valid_datagen.flow_from_directory(  \n",
    "    validation_data_dir,                              \n",
    "    target_size          = (width_shape, height_shape),          \n",
    "    batch_size           = batch_size,\n",
    "    #save_to_dir         = '',             Aca ponemos una direccion si queremos guardar las imagenes transformadas y generadas.\n",
    "    class_mode           = 'categorical')\n",
    "\n",
    "##################################### Entrenamiento ################################################\n",
    "\n",
    "# Modelo preentrenado a ejecutar\n",
    "\n",
    "nb_train_samples      = train_generator.samples            # Numero de imagenes de entrenamiento.\n",
    "nb_validation_samples = validation_generator.samples       # Numero de imagenes de validacion.  \n",
    "\n",
    "image_input = Input(shape = (width_shape, height_shape, 3)) #Importamos imagenes con formato: Ancho x alto x 3 canales RGB\n",
    "\n",
    "if  modelVGG == 16:\n",
    "    model = VGG16(input_tensor = image_input, include_top=True,weights='imagenet') #Cargamos modelo con parametros:\n",
    "                                                                                                    # Imagen de entrada\n",
    "                                                                                                    # Incluye ultima capa\n",
    "                                                                                                    # Conserva pesos preentrenado de dataset imagenet\n",
    "else: #VGG19\n",
    "    model = VGG19(input_tensor = image_input, include_top=True,weights='imagenet')\n",
    "    \n",
    "last_layer = model.get_layer('fc2').output                                     # Tomamos ultima capa del modelo\n",
    "out = Dense(num_classes, activation ='softmax', name ='output')(last_layer)    # Agregamos a ultima capa una capa densa que tiene como salida el numero de clases.\n",
    "custom_vgg_model = Model(image_input, out)                                     # compilamos el modelo.\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-1]:                                     # Transfer learning utilizado para tomar 'pesos' de otros modelos ya entrenados con \n",
    "\tlayer.trainable = False                                                    # distitos dataset de imagenes. Solo entrenaremos la ultima capa.\n",
    "                                                   \n",
    "\n",
    "custom_vgg_model.compile(loss = 'categorical_crossentropy',optimizer = 'adadelta',metrics = ['accuracy'])   # Compilamos modelo, con funcion loss, optimizador y metrica para el entrenamiento.\n",
    "\n",
    "custom_vgg_model.summary()                                                     # Utilizado para ver la estructura del modelo\n",
    "\n",
    "# Solo entrenamos la ultima capa del summary, la cual posee 4097 parametros por cantidad de clase, conservando el preentrenamiento\n",
    "# que trae el modelo de manera predefinida.\n",
    "\n",
    "model_history = custom_vgg_model.fit_generator(   \n",
    "    train_generator,                                 \n",
    "    epochs           = epochs,\n",
    "    validation_data  = validation_generator,\n",
    "    steps_per_epoch  = nb_train_samples//batch_size,\n",
    "    validation_steps = nb_validation_samples//batch_size)                      # Etapa de entrenamiento\n",
    "\n",
    "custom_vgg_model.save(model_dir)           # Guardado de modelo\n",
    "\n",
    "########################## Graficas de entrenamiento y validacion ####################################\n",
    "\n",
    "def plotTraining(hist, epochs, typeData):\n",
    "    \n",
    "    if typeData == \"loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc = hist.history['loss']\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Perdida', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Perdida en entrenamiento')\n",
    "        \n",
    "    if typeData==\"accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc = hist.history['accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Precisión (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'-r',label='Precisión en entrenamiento')\n",
    "        \n",
    "    if typeData == \"val_loss\":\n",
    "        plt.figure(1,figsize=(10,5))\n",
    "        yc = hist.history['val_loss']\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Perdida', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Perdida en validación')\n",
    "        \n",
    "    if typeData == \"val_accuracy\":\n",
    "        plt.figure(2,figsize=(10,5))\n",
    "        yc = hist.history['val_accuracy']\n",
    "        for i in range(0, len(yc)):\n",
    "            yc[i]=100*yc[i]\n",
    "        xc = range(epochs)\n",
    "        plt.ylabel('Precisión (%)', fontsize=24)\n",
    "        plt.plot(xc,yc,'--b',label='Precisión en validación')\n",
    "        \n",
    "\n",
    "    plt.rc('xtick',labelsize=24)\n",
    "    plt.rc('ytick',labelsize=24)\n",
    "    plt.rc('legend', fontsize=18) \n",
    "    plt.legend()\n",
    "    plt.xlabel('Numero de epocas',fontsize=24)\n",
    "    plt.grid(True)\n",
    "\n",
    "# Plot history:  Graficamos valores obtenidos en el entrenamiento\n",
    "\n",
    "plotTraining(model_history,epochs,\"loss\")                \n",
    "plotTraining(model_history,epochs,\"accuracy\")\n",
    "plotTraining(model_history,epochs,\"val_loss\")\n",
    "plotTraining(model_history,epochs,\"val_accuracy\")\n",
    "\n",
    "############################## Metricas de desempeño y matriz de confusion ##########################\n",
    "\n",
    "custom_Model = load_model(model_dir)\n",
    "\n",
    "names = ['Carpincho','Ciervo','Gato montes','Oveja','Puma','Vaca'] # Etiquetas para la matriz\n",
    "\n",
    "test_datagen  = ImageDataGenerator()                                # Generacion de imagenes\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(                 \n",
    "    test_data_dir,\n",
    "    target_size   = (width_shape, height_shape), \n",
    "    batch_size    = batch_size,\n",
    "    class_mode    = 'categorical', \n",
    "    shuffle       = False)           #Para que cargue el dataset en orden\n",
    "\n",
    "preds  = custom_Model.predict_generator(generator=test_generator)   # Realizacion de la prediccion\n",
    "\n",
    "y_pred = np.argmax(preds, axis=1)                                   # Se asigna clase segun valor maximo de probabilidad.\n",
    "y_real = test_generator.classes                                     # Clase REAL.\n",
    "\n",
    "matc   = confusion_matrix(y_real, y_pred)                           # Generacion de matriz de prediccion.\n",
    "\n",
    "plot_confusion_matrix(conf_mat=matc, figsize=(9,9), class_names = names, show_normed=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "print(metrics.classification_report(y_real,y_pred, digits = 4))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "54f46857",
   "metadata": {
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c87419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44848272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
